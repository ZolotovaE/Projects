# -*- coding: utf-8 -*-
"""МО_проект.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pyae8jBZHXWqZDHepFX4-rxzEdRi4Fgf
"""

!python.exe -m pip install --upgrade pip
!pip install numpy
!pip install pandas
!pip install scikit-learn
!pip install openpyxl
!pip install doubleml
! pip install linearmodels
! pip install pgmpy

# Подключим необходимые библиотеки
import numpy as np
import pandas as pd
import scipy as scipy
from copy import deepcopy
import math
from scipy.stats import multivariate_normal
import matplotlib.pyplot as plt
from scipy.stats import t, chi2, f, norm, poisson, binom, uniform, expon, logistic
import seaborn as sns
from sklearn.model_selection import train_test_split
import networkx as nx
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
import statsmodels.formula.api as smf
from linearmodels.iv import IV2SLS
import doubleml as dml
from sklearn.ensemble import RandomForestClassifier       # случайный лес (классификация)
from sklearn.ensemble import RandomForestRegressor        # случайный лес (регрессия)
from sklearn.ensemble import GradientBoostingClassifier   # градиентный бустинг (классификация)
from sklearn.ensemble import GradientBoostingRegressor    # градиентный бустинг (регрессия)
from sklearn.linear_model import Lasso                    # Лассо
from sklearn.base import clone
import statsmodels.api as sm                              # линейная регрессия
from sklearn.linear_model import LogisticRegression       # логистическая регрессия
from linearmodels.iv import IV2SLS, compare


from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import recall_score, precision_score, make_scorer
from pgmpy.models import DiscreteBayesianNetwork
from pgmpy.estimators import BayesianEstimator
from pgmpy.inference import VariableElimination

"""# 2. Генерация и предварительная обработка данных

# 2.1 - 2.2

**Зависимая переменная непрерывная** - кассовые сборы.

**Переменная воздействия бинарная** - факт наличия сцен 18+, то есть рейтинг R (1 - есть, 0 - нет).

**Инструментальная переменная** - переменная, отвечающая за жанры, в которых режиссер снимал в прошлом (1 - ранее снимал фильмы с возрастным рейтингом R, 0 иначе).

**Контрольные переменные**:

*   сиквел (бинарная, 1 -- если фильм является продолжением серии фильмов, 0 иначе).
*   оценки пользователей (непрерывная).
*   бюджет (непрерывная, в млн долларов)
"""

# Для воспроизводимости
np.random.seed(123)

# Число наблюдений
n = 10000

"""# 2.3

--- Контрольные переменные ---
"""

# Сиквел (бинарная переменная)
sequel = np.random.binomial(1, 0.3, size=n)

# Оценки пользователей (непрерывная переменная от 0 до 10)
ratings = np.clip(norm.rvs(loc=6.5, scale=1.0, size=n), 0, 10)

# Бюджет фильма (в млн долларов)
budget = np.clip(norm.rvs(loc=88, scale=10, size=n), 5, 450)

"""--- Инструментальная переменная: жанры, в которых режиссер снимал раньше ---"""

genre_index = (
    0.3 * ratings +                     # разумный вклад рейтинга
    1.5 * sequel                       # умеренное влияние сиквела
     - 4                             # СДВИГ уменьшен для балансировки вероятностей
)

# Немного шума, чтобы значения не слипались
genre_index += np.random.normal(0, 1.0, size=n)

# Вероятность
genre_prob = logistic.cdf(genre_index/2)

# Бинарная переменная
director_past_genre = np.random.binomial(1, genre_prob)

# Проверим долю единиц
print("Доля единиц в director_past_genre:", director_past_genre.mean())

""" --- Переменная воздействия: рейтинг R ---"""

# Эндогенная переменная - может зависеть от жанров, бюджета, оценок
rating_index = 2.2 * director_past_genre + 0.01 * budget  + 0.1 * ratings + 0.001*budget**2 + 0.07*np.log(ratings+1) - 8 + 0.002 *director_past_genre*ratings
rating_prob = logistic.cdf(rating_index)
rating_r = (uniform.rvs(size=n) < rating_prob).astype(int)

# Проверка доли единиц
print("Доля фильмов с рейтингом R:", np.mean(rating_r))

""" --- Зависимая переменная: кассовые сборы ---"""

# Ошибки
error0 = t.rvs(df=10, size=n) * 8
error1 = (expon.rvs(size=n, scale=25) - 10) + 0.001 * budget

# Моделируем сборы в зависимости от наличия рейтинга R
# С рейтингом R
g1 = -2* np.log(ratings + 1) + 1.0 * budget + 12 * sequel - 0.03 * budget *  + 0.3 * director_past_genre

# 0 — нет рейтинга R
g0 = -1.5 * np.log(ratings + 1) + 1.3 * budget + 10 * sequel + 0.017 * ratings**2 + 0.6 *director_past_genre

# Сборы
revenue = rating_r * (g1 + error1) + (1 - rating_r) * (g0 + error0) + 140

"""Датафрейм"""

df = pd.DataFrame({
    'revenue': revenue,
    'rating_r': rating_r,
    'sequel': sequel,
    'ratings': ratings,
    'budget': budget,
    'director_past_genre': director_past_genre
})

# --- Корреляционная матрица ---
print("\nКорреляционная матрица:")
print(df.corr(numeric_only=True).round(2))

df.corr(numeric_only=True).round(2)

df[['revenue', 'budget', 'ratings']].mean()

"""Проверка мулльтиколлинеарности"""

X = sm.add_constant(df[['budget', 'rating_r', 'revenue']])
vif_data = pd.DataFrame()
vif_data['переменная'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif_data

"""VIF для переменных оказался ниже 10, что говорит об отсутствии мультиколлинеарности

Описательные статистики
"""

df[['revenue', 'ratings', 'budget']].describe().loc[['mean', 'std', '50%', 'min', 'max']]

print("\nОписательные статистики для непрерывных переменных:")
print(df[['revenue', 'ratings', 'budget']].describe().loc[['mean', 'std', '50%', 'min', 'max']])

print("\nОписательные статистики для бинарных переменных:")
for var in ['rating_r', 'director_past_genre', 'sequel']:
    count = df[var].sum()
    share = count / n
    print(f"{var}: доля = {share:.3f}, количество = {count}")

# Визуализация распределения сборов
sns.histplot(df['revenue'], bins=50, kde=True, color='skyblue')
plt.title('Распределение кассовых сборов')
plt.xlabel('Кассовые сборы (млн $)')
plt.ylabel('Плотность')
plt.show()

"""Доля единиц выполняется для всех бинарных переменных, а число наблюдений больше 1000

# 2.4
"""

# Разделение на обучающую и тестовую выборку (25% в тест)
train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)

# Проверка размеров
print(f"Размер обучающей выборки: {train_df.shape}")
print(f"Размер тестовой выборки: {test_df.shape}")

"""# 2.5

Проверка валидности и релевантности инструмента

Релевантность через F-статистику первого шага 2МНК
"""

# Релевантность инструмента
# Первый шаг: rating_r - зависимая переменная, а инструмент - director_past_genre
first_stage = smf.ols('rating_r ~ director_past_genre + budget + ratings + sequel', data=df).fit()
first_stage.summary()

# F-статистика на значимость инструмента:
f_stat = first_stage.f_test("director_past_genre = 0")
print("\nF-статистика на значимость инструмента:")
print(f_stat)

"""Результат: F-статистика больше 10, p-value околонулевое, что говорит о релевантности инструмента.

Валидность

IV-регрессия: зависимая переменная — revenue, эндогенная — rating_r, инструмент — director_past_genre
"""

# IV модель
iv_model = IV2SLS.from_formula(
    'revenue ~ 1 + budget + ratings + sequel + [rating_r ~ director_past_genre]',
    data=df
).fit()

# OLS (просто регрессия без инструмента)
ols_model = IV2SLS.from_formula(
    'revenue ~ 1 + budget + ratings + sequel + rating_r',
    data=df
).fit()

# Сравнение моделей
comparison = compare({'OLS': ols_model, 'IV': iv_model})
comparison

"""Результаты: Инструмент director_past_genre — валидный (не коррелирует с ошибками) и релевантный (значимо влияет на rating_r)

# 3. Классификация

## 3.1. Выбор признаков для классификации

Целевая переменная:

rating_r — факт наличия сцен 18+ (1 — есть, 0 — нет)

Используемые признаки:

- sequel — сиквел (контрольная переменная)
- ratings — пользовательские оценки (контрольная переменная)
- budget — бюджет (контрольная переменная)

Обоснование выбора каждого признака:

- sequel - сиквелы часто наследуют рейтинг предыдущих фильмов серии.
- ratings - оценки пользователей могут отражать особенности аудитории и косвенно — наличие сцен 18+.
- budget - бюджет может влиять на жанр и целевую аудиторию фильма, а значит и на вероятность наличия сцен 18+.

## 3.2. Выбор моделей, обоснование и реализация

- Логистическая регрессия - классическая интерпретируемая модель для бинарной классификации. Хорошо работает при линейных зависимостях между признаками и целевой переменной. Позволяет оценить вклад каждого признака.
- Случайный лес (Random Forest) - мощный ансамблевый метод, устойчив к выбросам и мультиколлинеарности, хорошо работает с разными типами признаков, автоматически оценивает важность признаков.
- Метод k-ближайших соседей (KNN) - простой и интуитивный метод, не делает предположений о распределении данных, хорошо работает при небольшом числе признаков и несложных границах классов.
"""

# Признаки и целевая переменная
features = ['sequel', 'ratings', 'budget']
target = 'rating_r'

X_train = train_df[features]
y_train = train_df[target]
X_test = test_df[features]
y_test = test_df[target]

# Масштабирование для KNN и логистической регрессии
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Логистическая регрессия
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train_scaled, y_train)

# Случайный лес
rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf.fit(X_train, y_train)

# KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)

results = []

# Логистическая регрессия
train_acc_logreg = accuracy_score(y_train, logreg.predict(X_train_scaled))
test_acc_logreg = accuracy_score(y_test, logreg.predict(X_test_scaled))
cv_acc_logreg = cross_val_score(logreg, X_train_scaled, y_train, cv=5, scoring='accuracy').mean()
results.append(['Logistic Regression', train_acc_logreg, test_acc_logreg, cv_acc_logreg])

# Случайный лес
train_acc_rf = accuracy_score(y_train, rf.predict(X_train))
test_acc_rf = accuracy_score(y_test, rf.predict(X_test))
cv_acc_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy').mean()
results.append(['Random Forest', train_acc_rf, test_acc_rf, cv_acc_rf])

# KNN
train_acc_knn = accuracy_score(y_train, knn.predict(X_train_scaled))
test_acc_knn = accuracy_score(y_test, knn.predict(X_test_scaled))
cv_acc_knn = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy').mean()
results.append(['KNN', train_acc_knn, test_acc_knn, cv_acc_knn])

# Таблица результатов
results_df = pd.DataFrame(results, columns=['Model', 'Train Accuracy', 'Test Accuracy', 'CV Accuracy'])
print(results_df)

"""## 3.3. Тюнинг гиперпараметров и сравнение моделей

Необходимо для каждой из трёх моделей подобрать оптимальные гиперпараметры с помощью кросс-валидации (GridSearchCV).

"""

# 1. Логистическая регрессия
logreg_params = {'C': [0.01, 0.1, 1, 10, 100]}
logreg_grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42),
                           logreg_params, cv=5, scoring='accuracy')
logreg_grid.fit(X_train_scaled, y_train)

# 2. Случайный лес
rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None]}
rf_grid = GridSearchCV(RandomForestClassifier(random_state=42),
                      rf_params, cv=5, scoring='accuracy')
rf_grid.fit(X_train, y_train)

# 3. KNN
knn_params = {'n_neighbors': [3, 5, 7, 9]}
knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')
knn_grid.fit(X_train_scaled, y_train)

# Функция для сбора результатов
def get_results(model, grid, Xtr, Xte, ytr, yte):
    # До тюнинга
    base_model = model
    base_model.fit(Xtr, ytr)
    base_train_acc = accuracy_score(ytr, base_model.predict(Xtr))
    base_test_acc = accuracy_score(yte, base_model.predict(Xte))
    base_cv_acc = cross_val_score(base_model, Xtr, ytr, cv=5, scoring='accuracy').mean()
    # После тюнинга
    best_model = grid.best_estimator_
    best_train_acc = accuracy_score(ytr, best_model.predict(Xtr))
    best_test_acc = accuracy_score(yte, best_model.predict(Xte))
    best_cv_acc = grid.best_score_
    return [str(base_model), grid.param_grid, base_cv_acc, base_test_acc,
            grid.best_params_, best_cv_acc, best_test_acc]

results = []
results.append(get_results(LogisticRegression(max_iter=1000, random_state=42), logreg_grid, X_train_scaled, X_test_scaled, y_train, y_test))
results.append(get_results(RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42), rf_grid, X_train, X_test, y_train, y_test))
results.append(get_results(KNeighborsClassifier(n_neighbors=5), knn_grid, X_train_scaled, X_test_scaled, y_train, y_test))

results_df = pd.DataFrame(results, columns=[
    'Model (base)', 'Params grid', 'CV acc (base)', 'Test acc (base)',
    'Best params', 'CV acc (best)', 'Test acc (best)'
])
print(results_df)

"""## 3.3. OOB (out-of-bag) ошибка.


"""

# Сетка гиперпараметров
n_estimators_list = [50, 100, 200]
max_depth_list = [3, 5, 7, None]

best_oob_score = 0
best_params_oob = None
results_oob = []

for n_estimators in n_estimators_list:
    for max_depth in max_depth_list:
        rf_oob = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            oob_score=True,
            random_state=42,
            n_jobs=-1
        )
        rf_oob.fit(X_train, y_train)
        oob_score = rf_oob.oob_score_
        test_acc = accuracy_score(y_test, rf_oob.predict(X_test))
        results_oob.append({
            'n_estimators': n_estimators,
            'max_depth': max_depth,
            'OOB score': oob_score,
            'Test accuracy': test_acc
        })
        if oob_score > best_oob_score:
            best_oob_score = oob_score
            best_params_oob = (n_estimators, max_depth)

# Таблица результатов
results_oob_df = pd.DataFrame(results_oob)
print(results_oob_df)
print(f"\nЛучшие параметры по OOB: n_estimators={best_params_oob[0]}, max_depth={best_params_oob[1]}, OOB score={best_oob_score:.4f}")

"""## 3.4. Альтернативный критерий качества

F1-score — хороший выбор, если классы несбалансированы (у нас доля фильмов с рейтингом R ≈ 0.77).
"""

f1_scorer = make_scorer(f1_score)

# Логистическая регрессия
logreg_grid_f1 = GridSearchCV(
    LogisticRegression(max_iter=1000, random_state=42),
    {'C': [0.01, 0.1, 1, 10, 100]},
    cv=5, scoring=f1_scorer
)
logreg_grid_f1.fit(X_train_scaled, y_train)

# Случайный лес
rf_grid_f1 = GridSearchCV(
    RandomForestClassifier(random_state=42),
    {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None]},
    cv=5, scoring=f1_scorer
)
rf_grid_f1.fit(X_train, y_train)

# KNN
knn_grid_f1 = GridSearchCV(
    KNeighborsClassifier(),
    {'n_neighbors': [3, 5, 7, 9]},
    cv=5, scoring=f1_scorer
)
knn_grid_f1.fit(X_train_scaled, y_train)

# Логистическая регрессия
logreg_best_f1 = logreg_grid_f1.best_estimator_
f1_train_logreg = f1_score(y_train, logreg_best_f1.predict(X_train_scaled))
f1_test_logreg = f1_score(y_test, logreg_best_f1.predict(X_test_scaled))
f1_cv_logreg = logreg_grid_f1.best_score_

# Случайный лес
rf_best_f1 = rf_grid_f1.best_estimator_
f1_train_rf = f1_score(y_train, rf_best_f1.predict(X_train))
f1_test_rf = f1_score(y_test, rf_best_f1.predict(X_test))
f1_cv_rf = rf_grid_f1.best_score_

# KNN
knn_best_f1 = knn_grid_f1.best_estimator_
f1_train_knn = f1_score(y_train, knn_best_f1.predict(X_train_scaled))
f1_test_knn = f1_score(y_test, knn_best_f1.predict(X_test_scaled))
f1_cv_knn = knn_grid_f1.best_score_

# Таблица результатов
f1_results = pd.DataFrame([
    ['Logistic Regression', logreg_grid_f1.best_params_, f1_cv_logreg, f1_train_logreg, f1_test_logreg],
    ['Random Forest', rf_grid_f1.best_params_, f1_cv_rf, f1_train_rf, f1_test_rf],
    ['KNN', knn_grid_f1.best_params_, f1_cv_knn, f1_train_knn, f1_test_knn]
], columns=['Model', 'Best params (F1)', 'CV F1', 'Train F1', 'Test F1'])

print(f1_results)

"""## 3.4 Собственный критерий
Пример собственного критерия:
- "Взвешенная F1-метрика с приоритетом на полноту (Recall)"

Допустим, для задачи важнее не пропустить фильмы с рейтингом R (важна полнота), но при этом не хочется сильно терять в точности.

Custom Score = 0.7 $\cdot$ Recall + 0.3 $\cdot$ Precision

"""

def custom_score_func(y_true, y_pred):
    recall = recall_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    return 0.7 * recall + 0.3 * precision

custom_scorer = make_scorer(custom_score_func)

# Логистическая регрессия
logreg_grid_custom = GridSearchCV(
    LogisticRegression(max_iter=1000, random_state=42),
    {'C': [0.01, 0.1, 1, 10, 100]},
    cv=5, scoring=custom_scorer
)
logreg_grid_custom.fit(X_train_scaled, y_train)

# Случайный лес
rf_grid_custom = GridSearchCV(
    RandomForestClassifier(random_state=42),
    {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None]},
    cv=5, scoring=custom_scorer
)
rf_grid_custom.fit(X_train, y_train)

# KNN
knn_grid_custom = GridSearchCV(
    KNeighborsClassifier(),
    {'n_neighbors': [3, 5, 7, 9]},
    cv=5, scoring=custom_scorer
)
knn_grid_custom.fit(X_train_scaled, y_train)

# Логистическая регрессия
logreg_best_custom = logreg_grid_custom.best_estimator_
custom_train_logreg = custom_score_func(y_train, logreg_best_custom.predict(X_train_scaled))
custom_test_logreg = custom_score_func(y_test, logreg_best_custom.predict(X_test_scaled))
custom_cv_logreg = logreg_grid_custom.best_score_

# Случайный лес
rf_best_custom = rf_grid_custom.best_estimator_
custom_train_rf = custom_score_func(y_train, rf_best_custom.predict(X_train))
custom_test_rf = custom_score_func(y_test, rf_best_custom.predict(X_test))
custom_cv_rf = rf_grid_custom.best_score_

# KNN
knn_best_custom = knn_grid_custom.best_estimator_
custom_train_knn = custom_score_func(y_train, knn_best_custom.predict(X_train_scaled))
custom_test_knn = custom_score_func(y_test, knn_best_custom.predict(X_test_scaled))
custom_cv_knn = knn_grid_custom.best_score_

# Таблица результатов
custom_results = pd.DataFrame([
    ['Logistic Regression', logreg_grid_custom.best_params_, custom_cv_logreg, custom_train_logreg, custom_test_logreg],
    ['Random Forest', rf_grid_custom.best_params_, custom_cv_rf, custom_train_rf, custom_test_rf],
    ['KNN', knn_grid_custom.best_params_, custom_cv_knn, custom_train_knn, custom_test_knn]
], columns=['Model', 'Best params (Custom)', 'CV Custom', 'Train Custom', 'Test Custom'])

print(custom_results)

"""## 3.5. Построение ROC-кривых и сравнение по AUC

"""

plt.figure(figsize=(8, 6))

# Логистическая регрессия
y_score_logreg = logreg_best_f1.predict_proba(X_test_scaled)[:, 1]
fpr_logreg, tpr_logreg, _ = roc_curve(y_test, y_score_logreg)
auc_logreg = roc_auc_score(y_test, y_score_logreg)
plt.plot(fpr_logreg, tpr_logreg, label=f'Logistic Regression (AUC = {auc_logreg:.3f})')

# Случайный лес
y_score_rf = rf_best_f1.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)
auc_rf = roc_auc_score(y_test, y_score_rf)
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.3f})')

# KNN
y_score_knn = knn_best_f1.predict_proba(X_test_scaled)[:, 1]
fpr_knn, tpr_knn, _ = roc_curve(y_test, y_score_knn)
auc_knn = roc_auc_score(y_test, y_score_knn)
plt.plot(fpr_knn, tpr_knn, label=f'KNN (AUC = {auc_knn:.3f})')

# Диагональ случайного классификатора
plt.plot([0, 1], [0, 1], 'k--', label='Random')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривые моделей на тестовой выборке')
plt.legend()
plt.grid()
plt.show()

# Таблица AUC
auc_table = pd.DataFrame([
    ['Logistic Regression', auc_logreg],
    ['Random Forest', auc_rf],
    ['KNN', auc_knn]
], columns=['Model', 'AUC'])

print(auc_table)

"""## 3.5. Байесовская сеть

Построить ROC-кривую и вычислить AUC для Байесовской сети на тестовой выборке.

Описание простейшей структуры сети (DAG):

- sequel → rating_r
- ratings → rating_r
- budget → rating_r
"""

from pgmpy.models import DiscreteBayesianNetwork
from pgmpy.estimators import BayesianEstimator
from pgmpy.inference import VariableElimination

# Определим структуру сети (DAG)
model = DiscreteBayesianNetwork([
    ('sequel', 'rating_r'),
    ('ratings', 'rating_r'),
    ('budget', 'rating_r')
])

# Дискретизация непрерывных признаков для pgmpy (например, 4 бина)
from sklearn.preprocessing import KBinsDiscretizer

disc = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='quantile')
train_disc = train_df.copy()
test_disc = test_df.copy()
for col in ['ratings', 'budget']:
    train_disc[col] = disc.fit_transform(train_df[[col]])
    test_disc[col] = disc.transform(test_df[[col]])

# Обучение параметров сети
model.fit(train_disc, estimator=BayesianEstimator, prior_type='BDeu')

# Инференс
infer = VariableElimination(model)

# Получим вероятности для тестовой выборки
y_proba_bn = []
for _, row in test_disc.iterrows():
    q = infer.query(variables=['rating_r'], evidence={
        'sequel': int(row['sequel']),
        'ratings': int(row['ratings']),
        'budget': int(row['budget'])
    }, show_progress=False)
    y_proba_bn.append(q.values[1])  # вероятность rating_r=1

# ROC-кривая и AUC
from sklearn.metrics import roc_curve, roc_auc_score

fpr_bn, tpr_bn, _ = roc_curve(test_disc['rating_r'], y_proba_bn)
auc_bn = roc_auc_score(test_disc['rating_r'], y_proba_bn)

plt.figure(figsize=(8, 6))
plt.plot(fpr_bn, tpr_bn, label=f'Bayesian Network (AUC = {auc_bn:.3f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая Байесовской сети')
plt.legend()
plt.grid()
plt.show()

print(f"AUC Байесовской сети: {auc_bn:.3f}")

"""## 3.6. Матрица ошибок, оптимальный порог и прибыль

"""

from sklearn.metrics import confusion_matrix

# Пример для логистической регрессии (порог 0.5)
y_pred_logreg = (logreg_best_f1.predict_proba(X_test_scaled)[:, 1] >= 0.5).astype(int)
cm_logreg = confusion_matrix(y_test, y_pred_logreg)
print("Confusion matrix (Logistic Regression):\n", cm_logreg)

"""Пример цен ошибок:
- True Positive (TP): +100 (правильно найден фильм с рейтингом R)
- True Negative (TN): +10 (правильно найден фильм без рейтинга R)
- False Positive (FP): -20 (ошибочно помечен фильм как R)
- False Negative (FN): -50 (пропущен фильм с рейтингом R)
"""

def profit_curve(y_true, y_proba, thresholds, tp=100, tn=10, fp=-20, fn=-50):
    profits = []
    for thresh in thresholds:
        y_pred = (y_proba >= thresh).astype(int)
        tn_, fp_, fn_, tp_ = confusion_matrix(y_true, y_pred).ravel()
        profit = tp_ * tp + tn_ * tn + fp_ * fp + fn_ * fn
        profits.append(profit)
    return profits

# Для логистической регрессии
probas_train = logreg_best_f1.predict_proba(X_train_scaled)[:, 1]
thresholds = np.linspace(0, 1, 101)
profits = profit_curve(y_train, probas_train, thresholds)
best_thresh = thresholds[np.argmax(profits)]
print(f"Оптимальный порог для прибыли (LogReg): {best_thresh:.2f}")

# На тестовой выборке
probas_test = logreg_best_f1.predict_proba(X_test_scaled)[:, 1]
profit_test = profit_curve(y_test, probas_test, [best_thresh])[0]
auc_test = roc_auc_score(y_test, probas_test)
print(f"Прибыль на тесте (LogReg): {profit_test}, AUC: {auc_test:.3f}")

def profit_curve(y_true, y_proba, thresholds, tp=100, tn=10, fp=-20, fn=-50):
    profits = []
    for thresh in thresholds:
        y_pred = (y_proba >= thresh).astype(int)
        tn_, fp_, fn_, tp_ = confusion_matrix(y_true, y_pred).ravel()
        profit = tp_ * tp + tn_ * tn + fp_ * fp + fn_ * fn
        profits.append(profit)
    return profits

# Предсказания вероятностей
probas_train_rf = rf_best_f1.predict_proba(X_train)[:, 1]
probas_test_rf = rf_best_f1.predict_proba(X_test)[:, 1]

# Поиск оптимального порога на обучающей выборке
thresholds = np.linspace(0, 1, 101)
profits_rf = profit_curve(y_train, probas_train_rf, thresholds)
best_thresh_rf = thresholds[np.argmax(profits_rf)]
print(f"Оптимальный порог для прибыли (Random Forest): {best_thresh_rf:.2f}")

# Прибыль и матрица ошибок на тесте
profit_test_rf = profit_curve(y_test, probas_test_rf, [best_thresh_rf])[0]
y_pred_rf = (probas_test_rf >= best_thresh_rf).astype(int)
cm_rf = confusion_matrix(y_test, y_pred_rf)
auc_test_rf = roc_auc_score(y_test, probas_test_rf)
print("Confusion matrix (Random Forest):\n", cm_rf)
print(f"Прибыль на тесте (Random Forest): {profit_test_rf}, AUC: {auc_test_rf:.3f}")

# Предсказания вероятностей
probas_train_knn = knn_best_f1.predict_proba(X_train_scaled)[:, 1]
probas_test_knn = knn_best_f1.predict_proba(X_test_scaled)[:, 1]

# Поиск оптимального порога на обучающей выборке
profits_knn = profit_curve(y_train, probas_train_knn, thresholds)
best_thresh_knn = thresholds[np.argmax(profits_knn)]
print(f"Оптимальный порог для прибыли (KNN): {best_thresh_knn:.2f}")

# Прибыль и матрица ошибок на тесте
profit_test_knn = profit_curve(y_test, probas_test_knn, [best_thresh_knn])[0]
y_pred_knn = (probas_test_knn >= best_thresh_knn).astype(int)
cm_knn = confusion_matrix(y_test, y_pred_knn)
auc_test_knn = roc_auc_score(y_test, probas_test_knn)
print("Confusion matrix (KNN):\n", cm_knn)
print(f"Прибыль на тесте (KNN): {profit_test_knn}, AUC: {auc_test_knn:.3f}")

"""## 3.6. Пример собственной функции прибыли

Пусть прибыль за каждый True Positive (TP) уменьшается, если их слишком много подряд.
Или, например, штраф за False Positive увеличивается с каждым новым FP.

Пример функции:
- За каждый TP: +100, но если TP > 1800, то за каждый следующий TP: +50.
- За каждый FP: -20, но если FP > 500, то за каждый следующий FP: -100.
- TN и FN — как раньше.
"""

def custom_profit(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    # Базовые значения
    profit = 0
    # True Positive
    if tp <= 1800:
        profit += tp * 100
    else:
        profit += 1800 * 100 + (tp - 1800) * 50
    # False Positive
    if fp <= 500:
        profit += fp * -20
    else:
        profit += 500 * -20 + (fp - 500) * -100
    # True Negative
    profit += tn * 10
    # False Negative
    profit += fn * -50
    return profit

"""Поиск оптимального порога для модели"""

def custom_profit_curve(y_true, y_proba, thresholds):
    profits = []
    for thresh in thresholds:
        y_pred = (y_proba >= thresh).astype(int)
        profit = custom_profit(y_true, y_pred)
        profits.append(profit)
    return profits

# Для логистической регрессии
probas_train = logreg_best_f1.predict_proba(X_train_scaled)[:, 1]
thresholds = np.linspace(0, 1, 101)
profits_custom = custom_profit_curve(y_train, probas_train, thresholds)
best_thresh_custom = thresholds[np.argmax(profits_custom)]
print(f"Оптимальный порог для custom прибыли (LogReg): {best_thresh_custom:.2f}")

probas_test = logreg_best_f1.predict_proba(X_test_scaled)[:, 1]
profit_test_custom = custom_profit(y_test, (probas_test >= best_thresh_custom).astype(int))
print(f"Custom прибыль на тесте (LogReg): {profit_test_custom}")

# Random Forest
probas_train_rf = rf_best_f1.predict_proba(X_train)[:, 1]
profits_rf_custom = custom_profit_curve(y_train, probas_train_rf, thresholds)
best_thresh_rf_custom = thresholds[np.argmax(profits_rf_custom)]
print(f"Оптимальный порог для custom прибыли (Random forest): {best_thresh_rf_custom:.2f}")
probas_test_rf = rf_best_f1.predict_proba(X_test)[:, 1]
profit_test_rf_custom = custom_profit(y_test, (probas_test_rf >= best_thresh_rf_custom).astype(int))
print(f"Custom прибыль на тесте (Random Forest): {profit_test_rf_custom}")

# KNN
probas_train_knn = knn_best_f1.predict_proba(X_train_scaled)[:, 1]
profits_knn_custom = custom_profit_curve(y_train, probas_train_knn, thresholds)
best_thresh_knn_custom = thresholds[np.argmax(profits_knn_custom)]
print(f"Оптимальный порог для custom прибыли (KNN): {best_thresh_knn_custom:.2f}")
probas_test_knn = knn_best_f1.predict_proba(X_test_scaled)[:, 1]
profit_test_knn_custom = custom_profit(y_test, (probas_test_knn >= best_thresh_knn_custom).astype(int))
print(f"Custom прибыль на тесте (KNN): {profit_test_knn_custom}")

"""
## 3.7. Байесовская сеть: предполагаемый DAG, обучение структуры и сравнение

Обучение структуры Байесовской сети: Вместо того чтобы задавать структуру вручную, можно использовать алгоритмы обучения структуры из данных. Библиотека pgmpy поддерживает несколько таких алгоритмов (например, HillClimbSearch).
"""

from pgmpy.estimators import HillClimbSearch, BIC
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

model_defined = DiscreteBayesianNetwork([
    ('sequel', 'rating_r'),
    ('ratings', 'rating_r'),
    ('budget', 'rating_r')
])
model_defined.fit(train_disc, estimator=BayesianEstimator, prior_type='BDeu')
infer_defined = VariableElimination(model_defined)

y_proba_bn_defined = []
for _, row in test_disc.iterrows():
    evidence_dict = {
        'sequel': int(row['sequel']),
        'ratings': int(row['ratings']),
        'budget': int(row['budget'])
    }
    q = infer_defined.query(variables=['rating_r'], evidence=evidence_dict, show_progress=False)
    y_proba_bn_defined.append(q.values[1]) # Вероятность rating_r=1

auc_bn_defined = roc_auc_score(test_disc['rating_r'], y_proba_bn_defined)
print(f"AUC для предполагаемого DAG (ручная структура): {auc_bn_defined:.4f}")

# Обучение структуры DAG из данных
data_for_structure_learning = train_disc[['sequel', 'ratings', 'budget', 'rating_r']]

# HillClimbSearch - один из алгоритмов, BIC - одна из метрик оценки структуры
hc = HillClimbSearch(data=data_for_structure_learning)
best_model_structure = hc.estimate(scoring_method=BIC(data=data_for_structure_learning))
print("\nСтруктура, обученная алгоритмом HillClimbSearch:")
print(best_model_structure.edges())

model_learned_structure = DiscreteBayesianNetwork(best_model_structure.edges())
model_learned_structure.fit(data_for_structure_learning, estimator=BayesianEstimator, prior_type='BDeu')
infer_learned = VariableElimination(model_learned_structure)

y_proba_bn_learned = []
for _, row in test_disc.iterrows():
    evidence_dict_learned = {}
    predictor_nodes = [node for node in model_learned_structure.nodes() if node != 'rating_r' and node in row.index]
    for node in predictor_nodes:
        evidence_dict_learned[node] = int(row[node])
    q_learned = infer_learned.query(variables=['rating_r'], evidence=evidence_dict_learned, show_progress=False)
    y_proba_bn_learned.append(q_learned.values[1])

if len(y_proba_bn_learned) == len(test_disc['rating_r']):
    auc_bn_learned = roc_auc_score(test_disc['rating_r'], y_proba_bn_learned)
    print(f"AUC для DAG с обученной структурой: {auc_bn_learned:.4f}")

    # Сравнение ROC-кривых
    fpr_defined, tpr_defined, _ = roc_curve(test_disc['rating_r'], y_proba_bn_defined)
    fpr_learned, tpr_learned, _ = roc_curve(test_disc['rating_r'], y_proba_bn_learned)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr_defined, tpr_defined, label=f'Предполагаемый DAG (AUC = {auc_bn_defined:.3f})')
    plt.plot(fpr_learned, tpr_learned, label=f'Обученный DAG (AUC = {auc_bn_learned:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC-кривые для Байесовских сетей')
    plt.legend()
    plt.grid()
    plt.show()
else:
    print("Длины массивов для AUC не совпадают, пропуск расчета AUC для обученной структуры.")

"""## 3.8. Выбор лучшего и худшего классификатора

Для выбора лучшей и худшей модели будем использовать AUC на тестовой выборке как основной критерий, так как он комплексно оценивает способность модели разделять классы и устойчив к дисбалансу классов. В качестве дополнительного критерия можно рассмотреть F1-меру на тестовой выборке.

"""

print("--- AUC Scores ---")
print(auc_table)

print("\n--- F1 Scores (после тюнинга по F1) ---")
print(f1_results[['Model', 'Test F1']])

final_comparison_data = {
    'Model': ['Logistic Regression', 'Random Forest', 'KNN', 'Bayesian Network (Defined)', 'Bayesian Network (Learned)'],
    'AUC': [auc_logreg, auc_rf, auc_knn, auc_bn_defined, auc_bn_learned if 'auc_bn_learned' in locals() else 0.0],
    'Test F1': [f1_test_logreg, f1_test_rf, f1_test_knn, 0.0, 0.0]
}
final_df = pd.DataFrame(final_comparison_data)
final_df = final_df.sort_values(by='AUC', ascending=False)

print("\n--- Финальное сравнение моделей ---")
print(final_df)

best_model_name = final_df.iloc[0]['Model']
worst_model_name = final_df.iloc[-1]['Model']

print(f"\nЛучшая модель по AUC: {best_model_name} (AUC={final_df.iloc[0]['AUC']:.4f})")
print(f"Худшая модель по AUC: {worst_model_name} (AUC={final_df.iloc[-1]['AUC']:.4f})")

"""## 3.9. Повышенная сложность: дополнительный метод классификации
CatBoost (градиентный бустинг от Яндекса)

"""

!pip install catboost

from catboost import CatBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, roc_auc_score

cat_features_indices = [X_train.columns.get_loc(col) for col in ['director_past_genre', 'sequel'] if col in X_train.columns]

cb_model_base = CatBoostClassifier(verbose=0, random_state=42) # verbose=0 чтобы не было много вывода
cb_model_base.fit(X_train, y_train, cat_features=cat_features_indices if cat_features_indices else None)
y_pred_cb_base_test = cb_model_base.predict(X_test)
y_proba_cb_base_test = cb_model_base.predict_proba(X_test)[:, 1]

auc_cb_base_test = roc_auc_score(y_test, y_proba_cb_base_test)
print(f"CatBoost (базовый) - Test AUC: {auc_cb_base_test:.4f}")

# Сетка гиперпараметров не очень большая для простоты
params_cb = {
    'iterations': [100, 200],
    'depth': [4, 6],
    'learning_rate': [0.05, 0.1],
    'l2_leaf_reg': [1, 3]           # L2 регуляризация
}

cb_classifier = CatBoostClassifier(verbose=0, random_state=42, cat_features=cat_features_indices if cat_features_indices else None)

cb_grid = GridSearchCV(estimator=cb_classifier, param_grid=params_cb, cv=3, scoring='roc_auc', n_jobs=-1)
cb_grid.fit(X_train, y_train)

best_cb_model = cb_grid.best_estimator_
print(f"\nЛучшие параметры для CatBoost: {cb_grid.best_params_}")

y_pred_cb_tuned_test = best_cb_model.predict(X_test)
y_proba_cb_tuned_test = best_cb_model.predict_proba(X_test)[:, 1]

auc_cb_tuned_test = roc_auc_score(y_test, y_proba_cb_tuned_test)
print(f"CatBoost (тюнингованный) - Test AUC: {auc_cb_tuned_test:.4f}")

print(f"\nСравнение CatBoost с лучшей предыдущей моделью ({best_model_name}):")
print(f"AUC лучшей предыдущей модели: {final_df.iloc[0]['AUC']:.4f}")
print(f"AUC тюнингованного CatBoost: {auc_cb_tuned_test:.4f}")

"""# 4. Регрессия

# 4.1

Отбор признаков для прогнозирования: контрольные переменные (сиквел, бюджет и рейтинг)
"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
from sklearn.model_selection import cross_val_score, KFold

priznak = ['sequel', 'ratings', 'budget']
prognos = 'revenue'

X = df[priznak]
y = df[prognos]

# Разделение на обучающую и тестовую выборку (25% в тест)
train_df, test_df = train_test_split(df, test_size=0.25, random_state=42)

"""x - признаки

y - целевая переменная
"""

X_train = train_df[priznak]
y_train = train_df[prognos]
X_test = test_df[priznak]
y_test = test_df[prognos]

"""# 4.2

3 модели: для метода МНК, случайного леса и градиентного бустинга
"""

model_lr = LinearRegression()
model_rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
model_gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

model_lr.fit(X_train, y_train)
model_rf.fit(X_train, y_train) # обучение моделей
model_gb.fit(X_train, y_train)

"""Оценка через RMSE и MAPE"""

def evaluate_model(name, model, X_train, X_test, y_train, y_test):
    y_pred_train = model.predict(X_train) # предсказываем для обуч и тестовой выборки
    y_pred_test = model.predict(X_test)

    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train)) # берем корень из средней ошибки для RMSE
    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

    train_mape = mean_absolute_percentage_error(y_train, y_pred_train) # среднее значение для MAPE в процентах по определению
    test_mape = mean_absolute_percentage_error(y_test, y_pred_test)

    print(f"\n{name}")
    print(f"  RMSE train: {train_rmse:.2f}")
    print(f"  RMSE test: {test_rmse:.2f}")
    print(f"  MAPE train: {train_mape:.2%}")
    print(f"  MAPE test: {test_mape:.2%}")

    return {
        'train_rmse': train_rmse,
        'test_rmse': test_rmse,
        'train_mape': train_mape,
        'test_mape': test_mape
    }

results_lr = evaluate_model("Линейная модель МНК", model_lr, X_train, X_test, y_train, y_test)
results_rf = evaluate_model("Случайный лес", model_rf, X_train, X_test, y_train, y_test)
results_gb = evaluate_model("Градиентный бустинг", model_gb, X_train, X_test, y_train, y_test)

"""Через кросс-валидацию"""

def cross_validate_model(model, X, y, cv=5): # количество фолдов по умолчанию 5
    kf = KFold(n_splits=cv, shuffle=True, random_state=42) # создаем объект, который делит выборку на 5 частей
    # перемешиваем данные благодаря тру и фиксируем случайность для воспроизводимости
    rmse_scores = []
    mape_scores = [] # создаем пустые списки, где будут результаты значений

    for train_index, val_index in kf.split(X):
        X_tr, X_val = X.iloc[train_index], X.iloc[val_index] # создаем цикл по фолдам, какие сроки для обучения, а какие идут для валидации данных
        y_tr, y_val = y.iloc[train_index], y.iloc[val_index] # валидационная выборка

        model.fit(X_tr, y_tr)
        y_pred = model.predict(X_val)

        rmse = np.sqrt(mean_squared_error(y_val, y_pred)) # считаем значения из условия, чем меньше, тем лучше
        mape = mean_absolute_percentage_error(y_val, y_pred)

        rmse_scores.append(rmse)
        mape_scores.append(mape) # добавляем результаты в список и берем среднее по всем 5 фолдам

    print(f"  Кросс-валидация RMSE среднее: {np.mean(rmse_scores):.2f}")
    print(f"  Кросс-валидация MAPE среднее: {np.mean(mape_scores):.2%}")
    return rmse_scores, mape_scores

print("\nКросс-валидация на обучающей выборке")
print("Линейная регрессия МНК:")
cross_validate_model(model_lr, X_train, y_train)

print("\nСлучайный лес")
cross_validate_model(model_rf, X_train, y_train)

print("\nГрадиентный бустинг:")
cross_validate_model(model_gb, X_train, y_train)

"""# 4.3

Линейная регрессия МНК
"""

from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, make_scorer

# Убедимся, что нет NaN или Inf
X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()
y_train = y_train.loc[X_train.index]

lr = LinearRegression() # нет гиперпараметров у линейной
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Кросс-валидация
rmse_cv_lr = [] # для хранения RMSE по каждому фолду

for train_idx, val_idx in kf.split(X_train):
    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx] # индексы обучающего и валид набора
    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
    lr.fit(X_tr, y_tr) # обучаем на обуч части
    preds = lr.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, preds)) # вычисляем RMSE
    rmse_cv_lr.append(rmse) # сохраняем значения

cv_rmse_lr = np.mean(rmse_cv_lr) # среднее по всем фолдам

lr.fit(X_train, y_train) # переобучение модели на обуч выборке
test_rmse_lr = np.sqrt(mean_squared_error(y_test, lr.predict(X_test))) # на тестовой выборке для сравнения

"""Подбор гиперпараметров"""

from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import make_scorer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# RMSE (нужно отрицательное значение, чем больше лучше)
rmse_scorer = make_scorer(mean_squared_error, squared=False, greater_is_better=False)

# Параметры для тюнинга
param_grid_ridge = {'alpha': [0.1, 1.0, 10.0, 50.0]} # сила регуляризации
param_grid_lasso = {'alpha': [0.001, 0.01, 0.1, 1.0]} # чуть меньшие значения

"""Ридж регрессия"""

kf = KFold(n_splits=5, shuffle=True, random_state=42)
param_grid_ridge = {'ridge__alpha': [0.1, 1.0, 10.0, 50.0]}

# Стандартизация + Ridge
ridge_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('ridge', Ridge())
])

# Ridge регрессия с подбором гиперпараметров
grid_ridge = GridSearchCV(
    ridge_pipeline,
    param_grid_ridge,
    cv=kf,
    scoring='neg_root_mean_squared_error',
    n_jobs=-1
)
# обучает модель на 5 фолдах и вычисляет метрику
grid_ridge.fit(X_train, y_train)

best_ridge = grid_ridge.best_estimator_ # с лучшим значением альфа
cv_rmse_ridge_tuned = -grid_ridge.best_score_ # отрицательное число, поэтому меняем знак
test_rmse_ridge_tuned = np.sqrt(mean_squared_error(y_test, best_ridge.predict(X_test))) # предсказываем на тестовой выборке

"""Аналогично делаем тюнинг с лассо регрессией"""

kf = KFold(n_splits=5, shuffle=True, random_state=42)

param_grid_lasso = {'lasso__alpha': [0.001, 0.01, 0.1, 1.0]}

# Стандартизация + Lasso
lasso_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('lasso', Lasso(max_iter=10000))
])

grid_lasso = GridSearchCV(
    lasso_pipeline,
    param_grid_lasso,
    cv=kf,
    scoring='neg_root_mean_squared_error',
    n_jobs=-1
)
# увеличиваем число итераций
grid_lasso.fit(X_train, y_train)
best_lasso = grid_lasso.best_estimator_

cv_rmse_lasso_tuned = -grid_lasso.best_score_ # извлекаем лучшую модель и выбираем
test_rmse_lasso_tuned = np.sqrt(mean_squared_error(y_test, best_lasso.predict(X_test)))

print(f"Ridge best alpha: {grid_ridge.best_params_['ridge__alpha']}")
print(f"Ridge CV RMSE: {cv_rmse_ridge_tuned:.3f}, Test RMSE: {test_rmse_ridge_tuned:.3f}")

print(f"Lasso best alpha: {grid_lasso.best_params_['lasso__alpha']}")
print(f"Lasso CV RMSE: {cv_rmse_lasso_tuned:.3f}, Test RMSE: {test_rmse_lasso_tuned:.3f}")

results = pd.DataFrame({
    'Model': ['Linear Regression', 'Ridge Regression', 'Lasso Regression'],
    'Initial Params': ['-', 'alpha=[0.1, 1.0, 10.0, 50.0]', 'alpha=[0.001, 0.01, 0.1, 1.0]'],
    'Tuned Param': ['-', grid_ridge.best_params_, grid_lasso.best_params_],
    'CV RMSE': [round(cv_rmse_lr, 2), round(cv_rmse_ridge_tuned, 2), round(cv_rmse_lasso_tuned, 2)],
    'Test RMSE': [round(test_rmse_lr, 2), round(test_rmse_ridge_tuned, 2), round(test_rmse_lasso_tuned, 2)]
})
results

"""Случайный Лес"""

rf = RandomForestRegressor(n_estimators=100, random_state=42)
# модель случайного леса со 100 деревьями в ансамбле
rmse_cv_rf_init = [] # кросс-валидация для начальной модели

for train_idx, val_idx in kf.split(X_train):
    rf.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])
    preds = rf.predict(X_train.iloc[val_idx]) # аналогично коду выше, обучаем модель на текущем фолде
    rmse_cv_rf_init.append(np.sqrt(mean_squared_error(y_train.iloc[val_idx], preds))) # сохраняем результат RMSE

cv_rmse_rf_init = np.mean(rmse_cv_rf_init) # среднее по всем фолдам
test_rmse_rf_init = np.sqrt(mean_squared_error(y_test, rf.fit(X_train, y_train).predict(X_test))) # оценка на тестовой выборке

"""подбор гиперпараметров"""

param_grid_rf = {
    'n_estimators': [100, 200], # сколько деревьев в лесу
    'max_depth': [3, 5, None], # глубина без ограничения
    'min_samples_split': [2, 5], # минимальное число для разбиения узла
    'min_samples_leaf': [1, 2] # минимальное число объектов
}

grid_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=kf,
                       scoring='neg_root_mean_squared_error', n_jobs=-1) # отриц значение
grid_rf.fit(X_train, y_train)
best_rf = grid_rf.best_estimator_ # ищем наименьший RMSE

cv_rmse_rf_tuned = -grid_rf.best_score_
test_rmse_rf_tuned = np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test))) # после тюнинга

"""Градиентный бустинг"""

gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
rmse_cv_gb_init = [] # создание модели ГБ со скоростью обучения 0.1 и пустого списка

for train_idx, val_idx in kf.split(X_train): # запускаем цикл по разбиениям обуч выборки
    gb.fit(X_train.iloc[train_idx], y_train.iloc[train_idx]) # обучение модели на подвыборке и индексиуем строки
    preds = gb.predict(X_train.iloc[val_idx]) # предсказываем для вал части
    rmse_cv_gb_init.append(np.sqrt(mean_squared_error(y_train.iloc[val_idx], preds)))

# аналогично считаем среднеквадратичную ошибку между реальными и предсказанными
cv_rmse_gb_init = np.mean(rmse_cv_gb_init)
test_rmse_gb_init = np.sqrt(mean_squared_error(y_test, gb.fit(X_train, y_train).predict(X_test)))

"""Подбор гиперпараметров"""

param_grid_gb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5],
    'min_samples_split': [2, 5]
}

grid_gb = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid_gb, cv=kf,
                       scoring='neg_root_mean_squared_error', n_jobs=-1)
grid_gb.fit(X_train, y_train)
best_gb = grid_gb.best_estimator_

cv_rmse_gb_tuned = -grid_gb.best_score_
test_rmse_gb_tuned = np.sqrt(mean_squared_error(y_test, best_gb.predict(X_test)))

"""Результаты в таблице"""

results = pd.DataFrame({
    'Model': [
        'Linear Regression (OLS)',
        'Ridge Regression',
        'Lasso Regression',
        'Random Forest (Base)',
        'Random Forest (Tuned)',
        'Gradient Boosting (Base)',
        'Gradient Boosting (Tuned)'
    ],
    'Initial Params': [
        '-',
        'alpha=1.0',
        'alpha=1.0',
        'n_estimators=100',
        'various',
        'n_estimators=100, learning_rate=0.1',
        'various'
    ],
    'Tuned Params': [
        '-',
        str(grid_ridge.best_params_),
        str(grid_lasso.best_params_),
        '-',
        str(grid_rf.best_params_),
        '-',
        str(grid_gb.best_params_)
    ],
    'CV RMSE': [
        cv_rmse_lr,
        cv_rmse_ridge_tuned,
        cv_rmse_lasso_tuned,
        cv_rmse_rf_init,
        cv_rmse_rf_tuned,
        cv_rmse_gb_init,
        cv_rmse_gb_tuned
    ],
    'Test RMSE': [
        test_rmse_lr,
        test_rmse_ridge_tuned,
        test_rmse_lasso_tuned,
        test_rmse_rf_init,
        test_rmse_rf_tuned,
        test_rmse_gb_init,
        test_rmse_gb_tuned
    ]
})

results

"""Повышенная сложность"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.ensemble import RandomForestRegressor

kf = KFold(n_splits=5, shuffle=True, random_state=42)

"""Подбор гиперпараметров через OOB ошибку

Случайный лес

Используем RandomForestRegressor, который поддерживает OOB

"""

param_grid_rf = {
    'n_estimators': [100, 200],         # список значений количества деревьев в лесу, которые будем перебирать
    'max_depth': [3, 5, None],          # макс глубина дерева
    'min_samples_split': [2, 5],        # мин число образцов, необходимое для разделения узла; 2 и 5 - варианты
    'min_samples_leaf': [1, 2]          # мин число образцов в листовом узле; 1 или 2 для перебора
}

best_oob_score = np.inf # мин значение
best_params_oob = None # параметр, пока пустой

for n_est in param_grid_rf['n_estimators']: # цикл для каждого значения деревьев
    for depth in param_grid_rf['max_depth']: # для каждого глубины дерева
        for split in param_grid_rf['min_samples_split']: # для каждого мин
            for leaf in param_grid_rf['min_samples_leaf']: # для каждого значения
                rf = RandomForestRegressor(
                    n_estimators=n_est,
                    max_depth=depth,
                    min_samples_split=split,
                    min_samples_leaf=leaf,
                    oob_score=True, # включаем вычисление ошибки
                    random_state=42, # иксируем для воспроизводимости
                    n_jobs=-1 # используем доступные ядра
                )
                rf.fit(X_train, y_train)

                # OOB вычисляем ошибку
                oob_rmse = np.sqrt(mean_squared_error(y_train, rf.oob_prediction_))

                # Сохраняем лучшие параметры по OOB ошибке
                if oob_rmse < best_oob_score:
                    best_oob_score = oob_rmse # если текущая ошибка меньше сохраненного, обновляем лучший результат
                    best_params_oob = {
                        'n_estimators': n_est,
                        'max_depth': depth,
                        'min_samples_split': split,
                        'min_samples_leaf': leaf
                    }

print("Лучшие параметры по OOB:", best_params_oob)
print("OOB RMSE:", best_oob_score)

# Обучаем RF с лучшими параметрами и считаем RMSE на тесте
best_rf_oob = RandomForestRegressor(**best_params_oob, oob_score=True, random_state=42)
best_rf_oob.fit(X_train, y_train)
test_rmse_oob = np.sqrt(mean_squared_error(y_test, best_rf_oob.predict(X_test)))
print("Тестовый RMSE с OOB параметрами:", test_rmse_oob)

"""Подбор гиперпараметров через кросс-валидацию"""

param_grid_gb = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5],
    'learning_rate': [0.05, 0.1]
}

gb = GradientBoostingRegressor(random_state=42) # градиентный бустинг

grid_gb = GridSearchCV(
    gb,
    param_grid_gb,
    cv=kf,
    scoring='neg_root_mean_squared_error',
    n_jobs=-1
)

grid_gb.fit(X_train, y_train)

print("Лучшие параметры по CV:", grid_gb.best_params_)
print("CV RMSE (train):", -grid_gb.best_score_)

# Оцениваем на тестовой выборке
best_gb = grid_gb.best_estimator_
test_rmse_cv = np.sqrt(mean_squared_error(y_test, best_gb.predict(X_test)))
print("Тестовый RMSE с CV параметрами:", test_rmse_cv)

"""# 4.5

Повышенная сложность

Huber loss
"""

from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel, Matern
from sklearn.model_selection import GridSearchCV, train_test_split, KFold
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import make_scorer
import time

# Гиперпараметры
LEARNING_RATE = 0.01       # Скорость обучения
EPOCHS = 200               # Количество эпох
DELTA = 1.0                # Гиперпараметр Huber loss
BATCH_SIZE = 128

# Huber loss и его производная
def huber_loss(y_true, y_pred, delta):
    error = y_true - y_pred
    is_small_error = np.abs(error) <= delta
    squared_loss = 0.5 * error**2 # записываем функцию вывода значений
    linear_loss = delta * (np.abs(error) - 0.5 * delta)
    return np.where(is_small_error, squared_loss, linear_loss).mean()

def huber_gradient(X, y_true, y_pred, delta): # производная
    error = y_true - y_pred
    is_small_error = np.abs(error) <= delta
    grad = np.where(is_small_error, -error, -delta * np.sign(error))
    grad_w = X.T @ grad / len(y_true)
    grad_b = grad.mean()
    return grad_w, grad_b

# Обучение модели
def train_huber_regression(X_train, y_train, lr, delta, epochs, batch_size):
    n_samples, n_features = X_train.shape # пишем функцию
    weights = np.zeros(n_features)
    bias = 0.0

    history = [] # создаем пустой список

    for epoch in range(epochs):
        indices = np.random.permutation(n_samples)
        X_shuffled = X_train[indices]
        y_shuffled = y_train[indices]

        for start in range(0, n_samples, batch_size):
            end = start + batch_size
            X_batch = X_shuffled[start:end]
            y_batch = y_shuffled[start:end]

            y_pred = X_batch @ weights + bias # предсказываем значения по условной функции
            grad_w, grad_b = huber_gradient(X_batch, y_batch, y_pred, delta)

            weights -= lr * grad_w
            bias -= lr * grad_b

        y_epoch_pred = X_train @ weights + bias
        loss = huber_loss(y_train, y_epoch_pred, delta)
        history.append(loss)
        if epoch % 10 == 0:
            print(f"Epoch {epoch}, Huber Loss: {loss:.4f}")

    return weights, bias, history

# Преобразуем в numpy
X_train = train_df[priznak].values.astype(float)
y_train = train_df[prognos].values.astype(float)
X_test = test_df[priznak].values.astype(float)
y_test = test_df[prognos].values.astype(float)

# Масштабирование вручную
X_mean = X_train.mean(axis=0)
X_std = X_train.std(axis=0)
X_train_scaled = (X_train - X_mean) / X_std
X_test_scaled = (X_test - X_mean) / X_std

start = time.time() # сколько времени обучается

weights, bias, loss_history = train_huber_regression(
    X_train_scaled, y_train,
    lr=LEARNING_RATE,
    delta=DELTA,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE
)

end = time.time()

y_pred = X_test_scaled @ weights + bias

# Метрики
mse = np.mean((y_test - y_pred) ** 2)
r2 = 1 - (np.sum((y_test - y_pred)**2) / np.sum((y_test - np.mean(y_test))**2))

def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred)**2))

def r2_score(y_true, y_pred):
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    return 1 - ss_res / ss_tot

# Метрики
huber = huber_loss(y_test, y_pred, delta=1.0)
test_rmse = rmse(y_test, y_pred)
test_r2 = r2_score(y_test, y_pred)

print(f"\nМетрики на тестовой выборке:")
print(f"MSE: {mse:.4f}")
print(f"Huber Loss: {huber:.4f}")
print(f"RMSE: {test_rmse:.4f}")

"""Градиентный бустинг оказался лучшей моделью из ранее проведенных

# Задание 5. Эффекты воздействия

Объединение обучающей и тестовой выборки
"""

df.info() #исходный датафрейм, который будем использовать

"""# 5.2

Для выделения комплаеров введем гипотетические переменные рейтинга и не от чего независящую величину
"""

# Условная вероятность наличия у фильма рейтинга 18+
# Пороги
u = scipy.stats.uniform.rvs(size = n)

# Симулируем возрастной рейтинг фильма
# с режиссером, который до этого снимал такие фильмы
director_past_genre1 = 1
rating_r_prob1 = logistic.cdf(2.2 * director_past_genre1 + 0.01 * budget  + 0.1 * ratings + 0.001*budget**2 + 0.07*np.log(ratings+1) - 8 + 0.002 *director_past_genre1*ratings)
r1 = (rating_r_prob1 >= u).astype(int) #немного переименуем переменные для удобства

# Симулируем возрастной рейтинг фильма
# с режиссером, который до этого снимал разные фильмы
director_past_genre0 = 0
rating_r_prob0 = logistic.cdf(2.2 * director_past_genre0 + 0.01 * budget  + 0.1 * ratings + 0.001*budget**2 + 0.07*np.log(ratings+1) - 8 + 0.002 *director_past_genre0*ratings)
r0 = (rating_r_prob0 >= u).astype(int) #немного переименуем переменные для удобства

# Соблюдатели
compliers = r1 > r0

# Факт наличия у фильма рейтинга 18+
rating_r               = np.zeros(n)
rating_r[director_past_genre == 1] = r1[director_past_genre == 1]
rating_r[director_past_genre == 0] = r0[director_past_genre == 0]

# Доли фильмов с рейтингом 18+ и соблюдателей
print(pd.DataFrame(data    = [np.mean(compliers), np.mean(rating_r)],
                   index   = ['P(compliers = 1)', 'P(rating_r = 1)'],
                   columns = ['Оценка']))

#Кассовые сборы для разных ситуаций
revenue_0 = g0 + error0
revenue_1 = g1 + error1

#Наблюдаемые кассовые сборы
revenue = np.zeros(n)
revenue[rating_r == 0] = revenue_0[rating_r == 0]
revenue[rating_r == 1] = revenue_1[rating_r == 1]

data = pd.DataFrame({'rating_r': rating_r,  'budget': budget,
                   'ratings': ratings,   'sequel': sequel,
                   'director_past_genre': director_past_genre, 'revenue': revenue})
# Посмотрим на симулированные данные
data.head(10).style.format(precision = 2)

# Настоящие эффекты воздействия (не наблюдаются в данных)
TE = revenue_1 - revenue_0
print(TE[0:10])

"""Оценим средний эффект воздействия"""

# Точное приближение среднего эффекта воздействия, то есть
# с помощью оценки, недоступной с помощью реальных данных
ATE = np.mean(TE)

# Точное приближение локального среднего эффекта воздействия, то есть
# с помощью оценки, недоступной с помощью реальных данных
LATE = np.mean(TE[compliers])

results_table = pd.DataFrame({
    "Метрика": ["ATE (Средний эффект)", "LATE (Локальный средний эффект)"],
    "Значение": [ATE, LATE]})

results_table

from scipy.stats import gaussian_kde

# Рассчитываем индивидуальные эффекты воздействия
CATE = g1 - g0

# Создаем фигуру с двумя графиками
plt.figure(figsize=(14, 6))

# Гистограмма
plt.subplot(1, 2, 1)
sns.histplot(CATE, bins=30, kde=False, color='skyblue')
plt.axvline(x=np.mean(CATE), color='red', linestyle='--', label=f'ATE = {np.mean(CATE):.2f}')
plt.title('Гистограмма распределения CATE')
plt.xlabel('Эффект воздействия (млн $)')
plt.ylabel('Частота')
plt.legend()

# Ядерная оценка плотности
plt.subplot(1, 2, 2)
sns.kdeplot(CATE, fill=True, color='orange')
plt.axvline(x=np.mean(CATE), color='red', linestyle='--', label=f'ATE = {np.mean(CATE):.2f}')
plt.title('Ядерная оценка плотности CATE')
plt.xlabel('Эффект воздействия (млн $)')
plt.ylabel('Плотность')
plt.legend()

plt.tight_layout()
plt.show()

"""# 5.3

Оценивание ATE как разницы в средних
"""

# Наивная оценка как разница в выборочных средних
ATE_naive = np.mean(revenue[rating_r == 1]) - np.mean(revenue[rating_r == 0])

# Сравнение точного приближения и наивной оценки
print(pd.DataFrame(data    = [ATE, ATE_naive],
                   index   = ['ATE', 'ATE naive'],
                   columns = ['Оценка']))

"""# 5.4

Оценка с помощью метода наименьших квадратов
"""

# МНК оценивание для фильмов без сцен 18+
y0  = df.loc[rating_r == 0, ['revenue']]
x0  = df.loc[rating_r == 0, df.columns.drop(['revenue',	'rating_r','director_past_genre'])]
x0  = sm.add_constant(x0)
ls0 = sm.OLS(y0, x0).fit()

# МНК оценивание для фильмов со сценами 18+
y1  = df.loc[rating_r == 1, ['revenue']]
x1  = df.loc[rating_r == 1, df.columns.drop(['revenue',	'rating_r','director_past_genre'])]
x1  = sm.add_constant(x1)
ls1 = sm.OLS(y1, x1).fit()

#Оценим кассовые сборы при наличии или отсутствии рейтинга R

x = df.loc[:, df.columns.drop(['revenue',	'rating_r','director_past_genre'])]
x = sm.add_constant(x)
  # МНК оценка E(revenue0 | X) для всех фильмов
wage0_ls = ls0.predict(x)
  # МНК оценка E(revenue1 | X) для всех фильмов
wage1_ls = ls1.predict(x)

# Оценки CATE
CATE_ls = np.array(wage1_ls - wage0_ls)

# Оценка ATE как средняя разница в прогнозах МНК оценок
ATE_ls = np.mean(CATE_ls)

# Сравним результаты
print(pd.DataFrame(data    = [ATE, ATE_naive, ATE_ls],
                   index   = ['ATE', 'ATE naive', "ATE ls"],
                   columns = ['Оценка']))

"""Оценивание с помощью условных математических ожиданий"""

# Подготовка данных
X = df.drop(columns=['revenue', 'rating_r', 'director_past_genre'])
y = df['revenue']
T = df['rating_r']

# 1. Настройка модели градиентного бустинга
gb_params = {
    'n_estimators': 200,
    'learning_rate': 0.05,
    'max_depth': 5,
    'min_samples_split': 10,
    'random_state': 42
}

# Модель для фильмов со сценами 18+
gb1 = GradientBoostingRegressor(**gb_params).fit(X[T == 1], y[T == 1])

# Модель для фильмов без сцен 18+
gb0 = GradientBoostingRegressor(**gb_params).fit(X[T == 0], y[T == 0])

# Прогнозирование потенциальных исходов
y1_pred = gb1.predict(X)  # E[Y|X,T=1]
y0_pred = gb0.predict(X)  # E[Y|X,T=0]

# Оценка ATE
ATE_gb = np.mean(y1_pred - y0_pred)
print(f"ATE (градиентный бустинг): {ATE_gb:.2f}")

"""Оценка с помощью взвешивания на обратные вероятности"""

# Оценивание с помощью обратного взвешивания на вероятности IPW

# Подготовим данные
target   = df.loc[:, ['rating_r']]
features = df.loc[:, df.columns.drop(['revenue', 'rating_r', 'director_past_genre'])]

# Подготовим метод машинного обучения
gb = GradientBoostingClassifier(loss          = 'log_loss',
                                n_estimators  = 100,
                                learning_rate = 0.1)
gb.fit(features, target)

# Оценим условные вероятности P(educ = 1 | X)
prob_gb = gb.predict_proba(features)[:, 1]

# Оценим псевдоисходы
wage_pseudo = (revenue * rating_r) / prob_gb - (revenue * (1 - rating_r)) / (1 - prob_gb)

# Оценим ATE
ATE_IPW = np.mean(wage_pseudo)
print(ATE_IPW)

"""Оценим с помощью метода двойной устойчивости"""

# Подготовим данные
y = df.loc[:, ['revenue']]
x = df.loc[:, df.columns.drop(['revenue', 'director_past_genre'])]

# Подготовка модели
rf2 = GradientBoostingRegressor(n_estimators = 100,
                            max_depth    = 20,
                            max_features = 3)
rf2.fit(x, y)

x0         = deepcopy(x)
x0["rating_r"] = 0
revenue0_rf2  = rf2.predict(x0)

x1         = deepcopy(x)
x1["rating_r"] = 1
revenue1_rf2  = rf2.predict(x1)

# Оценим ATE с помощью DR метода с двойной устойчивостью
ATE_DR = np.mean((revenue1_rf2 - revenue0_rf2) + \
                 rating_r * (revenue - revenue1_rf2) / prob_gb - \
                 (1 - rating_r) * (revenue - revenue0_rf2) / (1 - prob_gb))
print(ATE_DR)

"""Оценим с помощью двойного машинного обучения

"""

# Данные в формате, необходимом для применения DML
dml_standard_data = dml.DoubleMLData(
                            data   = df,
                            y_col  = 'revenue',
                            d_cols = 'rating_r',
                            x_cols = ['budget', 'ratings', 'sequel'])

# Метод оценивания E(Y | X, T)
g_Y = GradientBoostingRegressor(n_estimators = 100,
                            max_depth    = 20,
                            max_features = 3)

# Метод оценивания E(T | X)
g_T = LogisticRegression(max_iter=1000, random_state=42)

# Подготовка объекта
dml_standard = dml.DoubleMLIRM(obj_dml_data = dml_standard_data,
                               ml_g         = g_Y,
                               ml_m         = g_T,
                               n_rep        = 1,
                               n_folds      = 5)

# Оценим параметры
dml_standard.fit()

# Сохраним оценку
ATE_dml_standard = dml_standard.coef[0]

# Сопоставим результаты
print(pd.DataFrame(data    = [ATE, ATE_naive, ATE_ls, ATE_gb, ATE_IPW, ATE_DR, ATE_dml_standard],
                   index   = ['ATE', 'ATE naive', 'ATE ls', 'ATE_gb','ATE_IPW', 'ATE_DR', 'ATE dml standard'],
                   columns = ['Оценка']))

"""Задание повышенной сложности: метод синтетического контроля"""

from sklearn.linear_model import LassoCV

def synthetic_control(X, T, y):
    treated = y[T==1].mean()
    control = X[T==0]


    model = LassoCV(cv=min(3, len(control)-1))
    model.fit(control.T, X[T==1].mean().values)
    weights = model.coef_
    weights = np.clip(weights, 0, None)  # Только положительные веса
    weights /= weights.sum()

    synthetic = (y[T==0] @ weights)
    return treated - synthetic

X = df.drop(columns=['revenue', 'rating_r', 'director_past_genre'])
y = df['revenue']
T = df['rating_r']
ate_sc = synthetic_control(X, T, y)
print(f"Synthetic Control ATE: {ate_sc:.2f}")

# Сопоставим результаты
print(pd.DataFrame(data    = [ATE, ATE_naive, ATE_ls, ATE_gb, ATE_IPW, ATE_DR, ATE_dml_standard, ate_sc],
                   index   = ['ATE', 'ATE naive', 'ATE ls', 'ATE_gb','ATE_IPW', 'ATE_DR', 'ATE dml standard', 'ATE_SC'],
                   columns = ['Оценка']))

"""# 5.5

Двойное машинное обучение без инструментальной переменной
"""

# Данные в формате, необходимом для применения DML
dml_standard2_data = dml.DoubleMLData(
                             data   = df,
                             y_col  = 'revenue',
                             d_cols = 'rating_r',
                             x_cols = ['ratings', 'sequel'])

# Подготовка объекта
dml_standard2 = dml.DoubleMLIRM(obj_dml_data = dml_standard2_data,
                                ml_g         = g_Y,
                                ml_m         = g_T,
                                n_rep        = 1,
                                n_folds      = 5)

# Оценим параметры
dml_standard2.fit()

# Посмотрим на результат
print(dml_standard2)

# Сохраним оценку
LATE_dml_standard2 = dml_standard2.coef[0]

"""Двойное машинное обучение с инструментальной переменной"""

# Данные в формате, необходимом для применения DML
dml_iv_data = dml.DoubleMLData(data   = df,
                               y_col  = 'revenue',
                               d_cols = 'rating_r',
                               z_cols = 'director_past_genre',
                               x_cols = ['ratings', 'sequel'])

# Метод оценивания E(Z | X)
g_Z = GradientBoostingClassifier(loss          = 'log_loss',
                                 n_estimators  = 100,
                                 learning_rate = 0.1)

# Подготовка объекта
dml_iv = dml.DoubleMLIIVM(obj_dml_data = dml_iv_data,
                          ml_g         = g_Y,
                          ml_m         = g_Z,
                          ml_r         = g_T,
                          n_rep        = 1,
                          n_folds      = 5)

# Оценим параметры
dml_iv.fit()

# Посмотрим на результат
print(dml_iv)

# Сохраним оценку
LATE_dml_iv = dml_iv.coef[0]

# Сопоставим результаты
print(pd.DataFrame(data    = [ATE, LATE, LATE_dml_standard2, LATE_dml_iv],
                   index   = ['ATE', 'LATE', 'LATE dml standard2', 'LATE dml iv',],
                   columns = ['Оценка']))

"""Повышенная сложность:"""

from statsmodels.discrete.discrete_model import Probit

X = df[['director_past_genre', 'budget', 'sequel', 'ratings']]
y = df['revenue']
T = df['rating_r']

# 1. Probit модель для отбора
probit = Probit(T, sm.add_constant(X)).fit(disp=0)
prob_treated = probit.predict(sm.add_constant(X))

# 2. 2SLS с поправкой Хекмана
# Inverse Mills ratio
lambda_ = probit.predict(sm.add_constant(X), linear=True) / probit.predict(sm.add_constant(X))

# Вторая стадия
X_2sls = sm.add_constant(pd.DataFrame({
    'rating_r': T,
    'budget': X['budget'],
    'sequel': X['sequel'],
    'ratings': X['ratings'],
    'lambda': lambda_
}))

model_2sls = sm.OLS(y, X_2sls).fit()

late_par = round(model_2sls.params['rating_r'], 2)

# LATE (коэфф. rating_r)
print(f"LATE estimate: {late_par}")

# Сопоставим результаты
print(pd.DataFrame(data    = [ATE, LATE, LATE_dml_standard2, LATE_dml_iv, late_par],
                   index   = ['ATE', 'LATE', 'LATE dml standard2', 'LATE dml iv', 'LATE par. model'],
                   columns = ['Оценка']))

"""# 5.6

Воспользуемся методом наименьших квадратов
"""

# Оценки CATE (код взят из пункта 5.4)
CATE_ls = np.array(wage1_ls - wage0_ls)
print(CATE_ls)

E_ls = np.mean(np.concatenate([wage0_ls, wage1_ls])) #для последующих пунктов

"""Воспользуемся методом S-learner"""

# CATE с помощью S-learner

# Подготовим данные
y = df.loc[:, ['revenue']]
x = df.loc[:, df.columns.drop(['revenue', 'director_past_genre'])]

# Подготовка модели
rf2 = GradientBoostingRegressor(n_estimators = 100,
                            max_depth    = 20,
                            max_features = 3)
rf2.fit(x, y)

x0         = deepcopy(x)
x0["rating_r"] = 0
revenue0_rf2  = rf2.predict(x0)

x1         = deepcopy(x)
x1["rating_r"] = 1
revenue1_rf2  = rf2.predict(x1)

# Оценки CATE
CATE_S = revenue1_rf2 - revenue0_rf2

E_S = np.mean(np.concatenate([revenue0_rf2, revenue1_rf2]))

"""Воспользуемся методом T-learner"""

# Подготовка данных
features = df.columns.drop(['revenue', 'director_past_genre', 'rating_r'])
X = df[features]
y = df['revenue']
T = df['rating_r']

# Добавляем константу для OLS
X_const = sm.add_constant(X)

# 1. МНК оценивание для фильмов без рейтинга R (T=0)
y0 = y[T == 0]
X0 = X_const[T == 0]
ls0 = sm.OLS(y0, X0).fit()

# 2. МНК оценивание для фильмов с рейтингом R (T=1)
y1 = y[T == 1]
X1 = X_const[T == 1]
ls1 = sm.OLS(y1, X1).fit()

# 3. Gradient Boosting модели
rf = GradientBoostingRegressor(n_estimators=100, max_depth=20, max_features=3)

# Обучение на группе T=0
rf0 = clone(rf).fit(X[T == 0], y[T == 0].values.ravel())  # Используем .ravel() для 1D массива

# Обучение на группе T=1
rf1 = clone(rf).fit(X[T == 1], y[T == 1].values.ravel())

# Предсказания для всех наблюдений
revenue0_pred = rf0.predict(X)
revenue1_pred = rf1.predict(X)

# Оценка CATE
CATE_T = revenue1_pred - revenue0_pred

E_T = np.mean(np.concatenate([revenue0_pred, revenue1_pred]))

"""Воспользуемся методом трансформации классов"""

# Оценим CATE методом трансформации классов

features = df.loc[:, df.columns.drop(['revenue', 'rating_r', 'director_past_genre'])]
target   = df.loc[:, ['rating_r']]


# Подготовим метод машинного обучения
gb = GradientBoostingClassifier(loss          = 'log_loss',
                                n_estimators  = 100,
                                learning_rate = 0.1)
gb.fit(features, target)

# Оценим условные вероятности
prob_gb = gb.predict_proba(features)[:, 1]

# Оценим псевдоисходы
wage_pseudo = (revenue * rating_r) / prob_gb - (revenue * (1 - rating_r)) / (1 - prob_gb)


rf3 = GradientBoostingRegressor(n_estimators = 100,
                            max_depth    = 5,
                            max_features = 3)
# Обучение модели
rf3.fit(features, wage_pseudo)

# Оценки CATE (метод трансформации классов)
CATE_CT = rf3.predict(features)

E_CT = np.mean(rf3.predict(features))

"""Воспользуемся методом X-learner"""

from sklearn.base import clone
from sklearn.model_selection import train_test_split
from sklearn.calibration import CalibratedClassifierCV

def x_learner_cate(X, T, y):
    # Шаг 1: Обучаем базовые модели (T-learner)
    model1 = GradientBoostingRegressor(n_estimators=100, max_depth=5).fit(
        X[T == 1], y[T == 1])
    model0 = GradientBoostingRegressor(n_estimators=100, max_depth=5).fit(
        X[T == 0], y[T == 0])

    # Прогнозы для всей выборки (для расчета общего среднего)
    pred1_all = model1.predict(X)  # Прогнозы как если бы все были T=1
    pred0_all = model0.predict(X)  # Прогнозы как если бы все были T=0
    prop_treated = np.mean(T)      # Доля наблюдений с T=1

    # Шаг 2: Вычисляем псевдо-эффекты
    # Для группы T=1: y_i - μ0(x_i)
    treated_idx = np.where(T == 1)[0]
    pseudo_effect_treated = y[T == 1] - model0.predict(X[T == 1])

    # Для группы T=0: μ1(x_i) - y_i
    control_idx = np.where(T == 0)[0]
    pseudo_effect_control = model1.predict(X[T == 0]) - y[T == 0]

    # Шаг 3: Обучаем модели на псевдо-эффектах
    tau1_model = GradientBoostingRegressor(n_estimators=100, max_depth=5).fit(
        X.iloc[treated_idx], pseudo_effect_treated)
    tau0_model = GradientBoostingRegressor(n_estimators=100, max_depth=5).fit(
        X.iloc[control_idx], pseudo_effect_control)

    # Шаг 4: Оцениваем propensity score
    ps_model = CalibratedClassifierCV(
        LogisticRegression(), cv=3).fit(X, T)
    ps = ps_model.predict_proba(X)[:, 1]
    ps = np.clip(ps, 0.1, 0.9)  # Избегаем крайних значений

    # Шаг 5: Комбинируем предсказания с весами
    tau1_pred = tau1_model.predict(X)
    tau0_pred = tau0_model.predict(X)

    # Взвешенное среднее
    cate = ps * tau0_pred + (1 - ps) * tau1_pred
    overall_pred = prop_treated * np.mean(pred1_all) + (1 - prop_treated) * np.mean(pred0_all)

    return cate, overall_pred


# Вычисляем CATE
cate_x, E_x = x_learner_cate(X, T, y)

"""Повышенная сложность: Casual Forest"""

from sklearn.base import BaseEstimator

class CausalForest(BaseEstimator):
    def __init__(self, n_estimators=100, min_samples_leaf=10):
        self.n_estimators = n_estimators
        self.min_samples_leaf = min_samples_leaf

    def fit(self, X, T, y):
        self.models = []
        for _ in range(self.n_estimators):
            # Бутстрап выборка
            idx = np.random.choice(len(X), size=len(X), replace=True)
            X_boot, T_boot, y_boot = X.iloc[idx], T.iloc[idx], y.iloc[idx]

            # Обучаем модель для treated и control
            rf1 = RandomForestRegressor(min_samples_leaf=self.min_samples_leaf)
            rf0 = RandomForestRegressor(min_samples_leaf=self.min_samples_leaf)

            rf1.fit(X_boot[T_boot==1], y_boot[T_boot==1])
            rf0.fit(X_boot[T_boot==0], y_boot[T_boot==0])

            self.models.append((rf1, rf0))
        return self

    def effect(self, X):
        effects = []
        for rf1, rf0 in self.models:
            effects.append(rf1.predict(X) - rf0.predict(X))
        return np.mean(effects, axis=0)

# Использование
causal_forest = CausalForest(n_estimators=100)
causal_forest.fit(X, T, y)
cate_cf = causal_forest.effect(X)

# Объединим полученные ранее оценки CATE
CATE_mat = pd.DataFrame({'True': CATE, 'LS': CATE_ls, 'S-learner': CATE_S,
                         'T-learner': CATE_T, 'Class Transformation': CATE_CT,'X-learner': cate_x, 'Casual Forest': cate_cf})
print(CATE_mat)

"""# 5.7"""

# Сравнение оценок CATE на основании истинных значений (по среднеквадратичной ошибке)
CATE_MSE0 = pd.DataFrame(data    = [np.mean((CATE_ls  - CATE) ** 2),
                                    np.mean((CATE_T   - CATE) ** 2),
                                    np.mean((CATE_S   - CATE) ** 2),
                                    np.mean((CATE_CT  - CATE) ** 2),
                                    np.mean((cate_x   - CATE) ** 2),
                                    np.mean((cate_cf   - CATE) ** 2)],
                         index   = ['LS', 'T-learner', 'S-learner', 'CT', 'X', 'Casual Forest'],
                         columns = ['MSE0'])
print(CATE_MSE0)

# Сравнение CATE на основании прогнозной точности моделей

CATE_MSE1 = pd.DataFrame(data    = [np.mean((revenue - E_ls) ** 2),
                                    np.mean((revenue - E_T) ** 2),
                                    np.mean((revenue - E_S) ** 2),
                                    np.mean((revenue - E_CT) ** 2),
                                    np.mean((revenue - E_x) ** 2)],
                         index   = ['LS', 'T-learner', 'S-learner', 'CT', 'X'],
                         columns = ['MSE1'])
print(CATE_MSE1)

# Сравнение CATE на основании псевдоисходов
CATE_MSE2 = pd.DataFrame(data    = [np.mean((wage_pseudo - CATE_ls) ** 2),
                                    np.mean((wage_pseudo - CATE_T) ** 2),
                                    np.mean((wage_pseudo - CATE_S) ** 2),
                                    np.mean((wage_pseudo - CATE_CT) ** 2),
                                    np.mean((wage_pseudo - cate_x) ** 2),
                                    np.mean((wage_pseudo - cate_cf) ** 2)],
                         index   = ['LS', 'T-learner', 'S-learner', 'CT', 'X', 'Casual Forest'],
                         columns = ['MSE2'])
print(CATE_MSE2)

"""# 5.8

Оценка с помощью метода двойного машинного обучения
"""

# Данные в формате, необходимом для применения DML
dml_standard_data = dml.DoubleMLData(
    data=df,
    y_col='revenue',
    d_cols='rating_r',
    x_cols=['budget', 'ratings', 'sequel'])

# Метод оценивания E(Y | X, T)
g_Y = RandomForestRegressor(n_estimators=100,
                          max_depth=20,
                          max_features=3,
                          random_state=42)

# Метод оценивания E(T | X) - исправленная версия
g_T = KNeighborsClassifier(n_neighbors=5)

# Подготовка объекта
dml_standard = dml.DoubleMLIRM(
    obj_dml_data=dml_standard_data,
    ml_g=g_Y,
    ml_m=g_T,
    n_rep=1,
    n_folds=5)

# Оценим параметры
dml_standard.fit()

# Сохраним оценку
ATE_dml_worst = dml_standard.coef[0]
print(f"ATE (DoubleML): {ATE_dml_worst:.4f}")

# Данные в формате, необходимом для применения DML
dml_iv_data = dml.DoubleMLData(data=df,
                              y_col='revenue',
                              d_cols='rating_r',
                              z_cols='director_past_genre',
                              x_cols=['ratings', 'sequel'])

# Метод оценивания E(Z | X)
g_Z = RandomForestClassifier(n_estimators=100,
                           max_depth=5,
                           random_state=42)

# Подготовка объекта
dml_iv = dml.DoubleMLIIVM(obj_dml_data=dml_iv_data,
                         ml_g=g_Y,
                         ml_m=g_Z,
                         ml_r=g_T,
                         n_rep=1,
                         n_folds=5)

# Оценим параметры
dml_iv.fit()

# Сохраним оценку
LATE_dml_iv_worst = dml_iv.coef[0]

# Сопоставим результаты
print(pd.DataFrame(data    = [ATE, ATE_naive, ATE_ls, ATE_gb, ATE_IPW, ATE_DR, ATE_dml_standard, ate_sc, ATE_dml_worst, LATE, LATE_dml_iv, late_par, LATE_dml_iv_worst],
                   index   = ['ATE', 'ATE naive', 'ATE ls', 'ATE_gb','ATE_IPW', 'ATE_DR', 'ATE dml standard', 'ATE_SC','ATE dml worst','LATE', 'LATE dml iv', 'LATE par. model', 'LATE_dml_iv_worst'],
                   columns = ['Оценка']))